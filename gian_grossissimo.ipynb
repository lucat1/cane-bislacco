{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lucat1/cane-bislacco/blob/main/gian_grossissimo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "L'obiettivo del progetto è apprendere mediante una rete neurale la trasformazione da punti del piano espressi in coordinate polari ad una rappresentazione basata su di una griglia discreta di dimensione 10x10, dove la cella della griglia ha valore 1 se contiene il punto, e 0 altrimenti.\n",
        "\n",
        "Il dataset supervisionato è fornito in questo notebook nella forma di una generatore. Il generatore deve essere considerato come una \"scatola nera\" il cui comportamento deve essere appreso. \n",
        "\n",
        "Dovete progettare una rete neurale in grado di raggiungere una accuratezza del 95%. Questa è una condizione necessaria per superare l'esame, ma l'accuratezza non influisce in altro modo sulla valutazione.  \n",
        "\n",
        "I modelli che raggiungono l'accuratezza attesa saranno invece valutati in modo inversamente proporzionale al numero dei loro parametri: **più il modello è piccolo, meglio è.**\n",
        "\n",
        "\n",
        "**Attenzione**: Qualunque soluzione che tragga vantaggio, diretto o indiretto, da meta-conoscenza relativa al generatore sarà automaticamente bocciato.\n"
      ],
      "metadata": {
        "id": "Zw_326KLT9dF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veniamo al generatore. Questo restituisce delle triple della forma\n",
        "((theta,rho),out) dove (theta,rho) sono le coordinate polari di un punto nel primo quadrante del piano, e out è una mappa 10x10 con \"1\" in correspondenza alla cella che contiene il punto, e \"0\" altrimenti.\n",
        "\n",
        "Settando  flat=True, la mappa 10x10 viene appiattita ad un vettore di dimensione 100. Potete utilizzare questa variante, se preferite. Nessuna altra modifica del generatore è ammessa. "
      ],
      "metadata": {
        "id": "iA01pkKbUt7Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creiamo una istanza del generatore con una griglia di dimensione 3x4"
      ],
      "metadata": {
        "id": "ZF-jlaqAWc2o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "... e osserviamo qualche esempio"
      ],
      "metadata": {
        "id": "b4hntQtSWjPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras import layers\n",
        "from keras import activations\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, Reshape, concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def polar_generator(batchsize,grid=(10,10),noise=.002,flat=False):\n",
        "  while True:\n",
        "    x = np.random.rand(batchsize)\n",
        "    y = np.random.rand(batchsize)\n",
        "    out = np.zeros((batchsize,grid[0],grid[1]))\n",
        "    xc = (x*grid[0]).astype(int)\n",
        "    yc = (y*grid[1]).astype(int)\n",
        "    for b in range(batchsize):\n",
        "      out[b,xc[b],yc[b]] = 1\n",
        "    #compute rho and theta and add some noise\n",
        "    rho = np.sqrt(x**2+y**2) + np.random.normal(scale=noise)\n",
        "    theta = np.arctan(y/np.maximum(x,.00001)) + np.random.normal(scale=noise)\n",
        "    if flat:\n",
        "      out = np.reshape(out,(batchsize,grid[0]*grid[1]))\n",
        "    yield ((theta,rho),out)\n",
        "\n",
        "n_train = 4000000\n",
        "n_test = 20000\n",
        "batch_size = 2048\n",
        "\n",
        "g1,g2 = 10,10\n",
        "gen = polar_generator(n_train+n_test,grid=(g1,g2),noise=0.002,flat=True)\n",
        "# (theta,rho),y = next(gen)\n",
        "(theta,rho),y = next(gen)\n",
        "\n",
        "x=np.array([i for i in zip(theta,rho)])\n",
        "\n",
        "# def xy(i):\n",
        "#   (theta,rho),y = i\n",
        "#   x=np.array([i for i in zip(theta,rho)])\n",
        "#   return (x,y)\n",
        "\n",
        "# gcd = np.gcd(n_train, n_test)\n",
        "# gen = pol.ipynbar_generator(gcd,grid=(size,size),noise=0.02)\n",
        "\n",
        "# x_train, y_train = xy(next(gen))\n",
        "# for i in range(int(n_train/gcd)-1):\n",
        "#   x,y = xy(next(gen))\n",
        "#   x_train = np.concatenate((x, x_train), axis=0)\n",
        "#   y_train = np.concatenate((y, y_train), axis=0)\n",
        "\n",
        "# x_test, y_test = xy(next(gen))\n",
        "# for i in range(int(n_train/gcd)-1):\n",
        "#   x,y = xy(next(gen))\n",
        "#   x_test = np.concatenate((x, x_test), axis=0)\n",
        "#   y_test = np.concatenate((y, y_test), axis=0)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=n_test/(n_train+n_test), shuffle=True, random_state=1)\n",
        "\n",
        "\n",
        "def discretized_accuracy(true_maps: tf.Tensor, my_maps: tf.Tensor) -> float:\n",
        "  equals = tf.equal(tf.argmax(true_maps, axis=1), tf.argmax(my_maps, axis=1))\n",
        "  return tf.cast(tf.math.count_nonzero(equals), tf.float64) / tf.cast(len(true_maps), tf.float64)"
      ],
      "metadata": {
        "id": "0Hh8TIUvKuXp"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "network = keras.Sequential([\n",
        "layers.Flatten(),\n",
        "# layers.Dense(20, activation=keras.activations.relu),\n",
        "# layers.Dense(20, activation=keras.activations.tanh),\n",
        "# layers.Dropout(0.1), # Spegni il 10% dei neuroni a caso\n",
        "layers.Dense(15, activation=keras.activations.relu),\n",
        "layers.Dense(10, activation=keras.activations.relu),\n",
        "# layers.BatchNormalization(),\n",
        "# layers.Dropout(0.5), # Spegni il 10% dei neuroni a caso\n",
        "layers.Dense(5, activation=keras.activations.relu),\n",
        "layers.Dense(5, activation=keras.activations.relu),\n",
        "# layers.Dropout(0.5), # Spegni il 10% dei neuroni a caso\n",
        "# layers.LayerNormalization(),\n",
        "# layers.BatchNormalization(),\n",
        "layers.Dense(100, activation=activations.softmax)\n",
        "])\n",
        "\n",
        "# Prima di poter usare il modello dobbiamo dire a Keras la dimensione dei nostri input\n",
        "# \"None\" vuol dire che il numero è ignoto/può cambiare (perché quante immagini alla volta g# può cambiare)\n",
        "network.build((None, 2))\n",
        "network.summary()\n",
        "\n",
        "network.compile(\n",
        "optimizer=keras.optimizers.Adam(learning_rate=1e-3), # Impostiamo SGD come ottimizzatore\n",
        "loss=keras.losses.CategoricalCrossentropy(),\n",
        "# loss=customLoss,\n",
        "metrics=['accuracy', discretized_accuracy]\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icsL8zRUZ1Y-",
        "outputId": "035be0be-6be5-4035-ad64-25b9780b2b60"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_1 (Flatten)         (None, 2)                 0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 15)                45        \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 10)                160       \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 5)                 55        \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 5)                 30        \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 100)               600       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 890\n",
            "Trainable params: 890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "network = keras.models.load_model(\"mymodel\")"
      ],
      "metadata": {
        "id": "lVV8wkELsrfz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "outputId": "19efa8aa-df36-4c76-b7f7-ea023e30f1da"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m network \u001b[38;5;241m=\u001b[39m \u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmymodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/usr/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[0;32m/usr/lib/python3.10/site-packages/keras/saving/legacy/saved_model/load.py:1138\u001b[0m, in \u001b[0;36mrevive_custom_object\u001b[0;34m(identifier, metadata)\u001b[0m\n\u001b[1;32m   1136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m revived_cls\u001b[38;5;241m.\u001b[39m_init_from_metadata(metadata)\n\u001b[1;32m   1137\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1138\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1139\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to restore custom object of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midentifier\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1140\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease make sure that any custom layers are included in the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1141\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`custom_objects` arg when calling `load_model()` and make sure \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1142\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthat all layers implement `get_config` and `from_config`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1143\u001b[0m     )\n",
            "\u001b[0;31mValueError\u001b[0m: Unable to restore custom object of type _tf_keras_metric. Please make sure that any custom layers are included in the `custom_objects` arg when calling `load_model()` and make sure that all layers implement `get_config` and `from_config`."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = network.fit(\n",
        "x=x_train,\n",
        "y=y_train,\n",
        "epochs=100, # Addestriamo per 100 epoche\n",
        "batch_size=batch_size # Usiamo una batch size di 128\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0s1bjWjlxkEv",
        "outputId": "d549e6e5-af00-402e-ddd4-e6aad9fbbce6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1954/1954 [==============================] - 62s 32ms/step - loss: 3.0941 - accuracy: 0.1222 - discretized_accuracy: 0.1223\n",
            "Epoch 2/100\n",
            "1954/1954 [==============================] - 65s 33ms/step - loss: 1.1171 - accuracy: 0.6255 - discretized_accuracy: 0.6256\n",
            "Epoch 3/100\n",
            "1954/1954 [==============================] - 63s 32ms/step - loss: 0.4497 - accuracy: 0.8546 - discretized_accuracy: 0.8546\n",
            "Epoch 4/100\n",
            "1954/1954 [==============================] - 67s 35ms/step - loss: 0.2847 - accuracy: 0.9091 - discretized_accuracy: 0.9091\n",
            "Epoch 5/100\n",
            "1954/1954 [==============================] - 61s 31ms/step - loss: 0.2220 - accuracy: 0.9303 - discretized_accuracy: 0.9303\n",
            "Epoch 6/100\n",
            "1954/1954 [==============================] - 61s 31ms/step - loss: 0.1899 - accuracy: 0.9400 - discretized_accuracy: 0.9400\n",
            "Epoch 7/100\n",
            "1954/1954 [==============================] - 63s 32ms/step - loss: 0.1698 - accuracy: 0.9455 - discretized_accuracy: 0.9454\n",
            "Epoch 8/100\n",
            "1954/1954 [==============================] - 65s 33ms/step - loss: 0.1553 - accuracy: 0.9496 - discretized_accuracy: 0.9496\n",
            "Epoch 9/100\n",
            "1954/1954 [==============================] - 66s 34ms/step - loss: 0.1456 - accuracy: 0.9516 - discretized_accuracy: 0.9516\n",
            "Epoch 10/100\n",
            "1954/1954 [==============================] - 64s 33ms/step - loss: 0.1375 - accuracy: 0.9538 - discretized_accuracy: 0.9538\n",
            "Epoch 11/100\n",
            "1954/1954 [==============================] - 67s 34ms/step - loss: 0.1319 - accuracy: 0.9548 - discretized_accuracy: 0.9548\n",
            "Epoch 12/100\n",
            "1954/1954 [==============================] - 63s 32ms/step - loss: 0.1260 - accuracy: 0.9567 - discretized_accuracy: 0.9567\n",
            "Epoch 13/100\n",
            "1954/1954 [==============================] - 67s 34ms/step - loss: 0.1218 - accuracy: 0.9575 - discretized_accuracy: 0.9575\n",
            "Epoch 14/100\n",
            "1954/1954 [==============================] - 67s 34ms/step - loss: 0.1183 - accuracy: 0.9581 - discretized_accuracy: 0.9581\n",
            "Epoch 15/100\n",
            "1954/1954 [==============================] - 67s 34ms/step - loss: 0.1154 - accuracy: 0.9588 - discretized_accuracy: 0.9588\n",
            "Epoch 16/100\n",
            "1954/1954 [==============================] - 69s 35ms/step - loss: 0.1125 - accuracy: 0.9595 - discretized_accuracy: 0.9595\n",
            "Epoch 17/100\n",
            "1954/1954 [==============================] - 65s 33ms/step - loss: 0.1094 - accuracy: 0.9605 - discretized_accuracy: 0.9605\n",
            "Epoch 18/100\n",
            "1954/1954 [==============================] - 66s 34ms/step - loss: 0.1076 - accuracy: 0.9608 - discretized_accuracy: 0.9608\n",
            "Epoch 19/100\n",
            "  26/1954 [..............................] - ETA: 1:12 - loss: 0.1102 - accuracy: 0.9586 - discretized_accuracy: 0.9586"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mnetwork\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Addestriamo per 100 epoche\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Usiamo una batch size di 128\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/usr/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m/usr/lib/python3.10/site-packages/keras/engine/training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1642\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1643\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1644\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1648\u001b[0m ):\n\u001b[1;32m   1649\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1650\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1651\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1652\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
            "File \u001b[0;32m/usr/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m/usr/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    877\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 880\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    882\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    883\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
            "File \u001b[0;32m/usr/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    909\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    910\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    911\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 912\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    914\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    915\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    916\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
            "File \u001b[0;32m/usr/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    132\u001b[0m   (concrete_function,\n\u001b[1;32m    133\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/usr/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1741\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1744\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1745\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1746\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1747\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m     args,\n\u001b[1;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1750\u001b[0m     executing_eagerly)\n\u001b[1;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
            "File \u001b[0;32m/usr/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    377\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 378\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    384\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    386\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    387\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    390\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    391\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
            "File \u001b[0;32m/usr/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score, _, acc  = network.evaluate(x_test, y_test,\n",
        "                            batch_size=batch_size)\n",
        "print('Test score:', score)\n",
        "print('Accuracy: {:.1f}%'.format(acc*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EVrd8vdibxj",
        "outputId": "716c01b6-3a46-4f0d-82de-214a1f920033"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1101 - accuracy: 0.9581 - discretized_accuracy: 0.9583\n",
            "Test score: 0.11012998968362808\n",
            "Accuracy: 95.8%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "network.save(\"mymodel_2048\")\n",
        "network.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYGzYU7dnM11",
        "outputId": "19d20ffd-0fb4-4841-f3fa-c2e521697c9a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: mymodel_2048/assets\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_1 (Flatten)         (None, 2)                 0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 15)                45        \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 10)                160       \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 5)                 55        \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 5)                 30        \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 100)               600       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 890\n",
            "Trainable params: 890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gen = polar_generator(20000,grid=(g1,g2),noise=0.002,flat=True)\n",
        "\n",
        "accs = 0.0\n",
        "iters = 100\n",
        "for x in range(iters):\n",
        "  (theta,rho),y = next(gen)\n",
        "  x=np.array([i for i in zip(theta,rho)])\n",
        "\n",
        "  score, _, acc = network.evaluate(x, y, batch_size=batch_size)\n",
        "  accs += acc\n",
        "\n",
        "print('Accuracy: {:.1f}%'.format(accs/iters*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSuIej-WhztW",
        "outputId": "ce6d65d7-b68d-4092-9f00-fe69468ce73e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2351 - accuracy: 0.9085 - discretized_accuracy: 0.9085\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1571 - accuracy: 0.9340 - discretized_accuracy: 0.9337\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.1466 - accuracy: 0.9400 - discretized_accuracy: 0.9400\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1265 - accuracy: 0.9483 - discretized_accuracy: 0.9483\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.1625 - accuracy: 0.9315 - discretized_accuracy: 0.9314\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.1336 - accuracy: 0.9461 - discretized_accuracy: 0.9462\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2091 - accuracy: 0.9170 - discretized_accuracy: 0.9170\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1245 - accuracy: 0.9486 - discretized_accuracy: 0.9485\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1706 - accuracy: 0.9297 - discretized_accuracy: 0.9297\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.1383 - accuracy: 0.9419 - discretized_accuracy: 0.9418\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.1415 - accuracy: 0.9391 - discretized_accuracy: 0.9392\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3196 - accuracy: 0.8865 - discretized_accuracy: 0.8865\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2013 - accuracy: 0.9185 - discretized_accuracy: 0.9186\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1403 - accuracy: 0.9423 - discretized_accuracy: 0.9423\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.1965 - accuracy: 0.9189 - discretized_accuracy: 0.9186\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1525 - accuracy: 0.9348 - discretized_accuracy: 0.9349\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1326 - accuracy: 0.9462 - discretized_accuracy: 0.9462\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.1675 - accuracy: 0.9293 - discretized_accuracy: 0.9291\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1831 - accuracy: 0.9243 - discretized_accuracy: 0.9245\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1918 - accuracy: 0.9204 - discretized_accuracy: 0.9208\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.1091 - accuracy: 0.9569 - discretized_accuracy: 0.9570\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1672 - accuracy: 0.9299 - discretized_accuracy: 0.9299\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2459 - accuracy: 0.9055 - discretized_accuracy: 0.9057\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1496 - accuracy: 0.9370 - discretized_accuracy: 0.9368\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.1890 - accuracy: 0.9234 - discretized_accuracy: 0.9236\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1930 - accuracy: 0.9227 - discretized_accuracy: 0.9228\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2063 - accuracy: 0.9172 - discretized_accuracy: 0.9175\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1165 - accuracy: 0.9535 - discretized_accuracy: 0.9535\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1384 - accuracy: 0.9418 - discretized_accuracy: 0.9417\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1614 - accuracy: 0.9291 - discretized_accuracy: 0.9289\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1870 - accuracy: 0.9245 - discretized_accuracy: 0.9245\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1452 - accuracy: 0.9394 - discretized_accuracy: 0.9396\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.1191 - accuracy: 0.9545 - discretized_accuracy: 0.9545\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1452 - accuracy: 0.9406 - discretized_accuracy: 0.9408\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2327 - accuracy: 0.9098 - discretized_accuracy: 0.9099\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.1393 - accuracy: 0.9410 - discretized_accuracy: 0.9411\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.1373 - accuracy: 0.9427 - discretized_accuracy: 0.9427\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.1195 - accuracy: 0.9520 - discretized_accuracy: 0.9520\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2117 - accuracy: 0.9150 - discretized_accuracy: 0.9151\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.1482 - accuracy: 0.9360 - discretized_accuracy: 0.9360\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1623 - accuracy: 0.9298 - discretized_accuracy: 0.9298\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1469 - accuracy: 0.9388 - discretized_accuracy: 0.9387\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.1638 - accuracy: 0.9321 - discretized_accuracy: 0.9322\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.1581 - accuracy: 0.9330 - discretized_accuracy: 0.9329\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1779 - accuracy: 0.9242 - discretized_accuracy: 0.9243\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.1242 - accuracy: 0.9484 - discretized_accuracy: 0.9481\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.1552 - accuracy: 0.9329 - discretized_accuracy: 0.9327\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.1904 - accuracy: 0.9209 - discretized_accuracy: 0.9208\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.1391 - accuracy: 0.9413 - discretized_accuracy: 0.9414\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2677 - accuracy: 0.8967 - discretized_accuracy: 0.8966\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.1727 - accuracy: 0.9265 - discretized_accuracy: 0.9265\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.1583 - accuracy: 0.9363 - discretized_accuracy: 0.9365\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.1487 - accuracy: 0.9390 - discretized_accuracy: 0.9390\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1286 - accuracy: 0.9461 - discretized_accuracy: 0.9460\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2394 - accuracy: 0.9058 - discretized_accuracy: 0.9056\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.1405 - accuracy: 0.9424 - discretized_accuracy: 0.9425\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.1182 - accuracy: 0.9531 - discretized_accuracy: 0.9531\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.1185 - accuracy: 0.9524 - discretized_accuracy: 0.9524\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1483 - accuracy: 0.9367 - discretized_accuracy: 0.9367\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.1212 - accuracy: 0.9507 - discretized_accuracy: 0.9507\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1101 - accuracy: 0.9559 - discretized_accuracy: 0.9557\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1186 - accuracy: 0.9541 - discretized_accuracy: 0.9542\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1384 - accuracy: 0.9433 - discretized_accuracy: 0.9432\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1646 - accuracy: 0.9302 - discretized_accuracy: 0.9302\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.1262 - accuracy: 0.9501 - discretized_accuracy: 0.9503\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1168 - accuracy: 0.9545 - discretized_accuracy: 0.9544\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.1401 - accuracy: 0.9420 - discretized_accuracy: 0.9418\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1758 - accuracy: 0.9272 - discretized_accuracy: 0.9271\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.1636 - accuracy: 0.9317 - discretized_accuracy: 0.9318\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.1429 - accuracy: 0.9413 - discretized_accuracy: 0.9415\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.1619 - accuracy: 0.9327 - discretized_accuracy: 0.9328\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1532 - accuracy: 0.9378 - discretized_accuracy: 0.9380\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1653 - accuracy: 0.9305 - discretized_accuracy: 0.9303\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1215 - accuracy: 0.9495 - discretized_accuracy: 0.9496\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1549 - accuracy: 0.9322 - discretized_accuracy: 0.9318\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.1102 - accuracy: 0.9560 - discretized_accuracy: 0.9561\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1721 - accuracy: 0.9295 - discretized_accuracy: 0.9295\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1585 - accuracy: 0.9329 - discretized_accuracy: 0.9332\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.1294 - accuracy: 0.9463 - discretized_accuracy: 0.9463\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1797 - accuracy: 0.9258 - discretized_accuracy: 0.9256\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1711 - accuracy: 0.9261 - discretized_accuracy: 0.9261\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.1898 - accuracy: 0.9212 - discretized_accuracy: 0.9212\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.1140 - accuracy: 0.9553 - discretized_accuracy: 0.9555\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.1582 - accuracy: 0.9339 - discretized_accuracy: 0.9338\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2216 - accuracy: 0.9137 - discretized_accuracy: 0.9138\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.1278 - accuracy: 0.9482 - discretized_accuracy: 0.9483\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.1126 - accuracy: 0.9566 - discretized_accuracy: 0.9567\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1328 - accuracy: 0.9460 - discretized_accuracy: 0.9460\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.1385 - accuracy: 0.9441 - discretized_accuracy: 0.9440\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1156 - accuracy: 0.9549 - discretized_accuracy: 0.9548\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1354 - accuracy: 0.9420 - discretized_accuracy: 0.9422\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2635 - accuracy: 0.8960 - discretized_accuracy: 0.8962\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1496 - accuracy: 0.9363 - discretized_accuracy: 0.9364\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.1270 - accuracy: 0.9491 - discretized_accuracy: 0.9492\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.1086 - accuracy: 0.9580 - discretized_accuracy: 0.9578\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1910 - accuracy: 0.9220 - discretized_accuracy: 0.9223\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.1357 - accuracy: 0.9413 - discretized_accuracy: 0.9415\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.1544 - accuracy: 0.9340 - discretized_accuracy: 0.9336\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1988 - accuracy: 0.9222 - discretized_accuracy: 0.9221\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1254 - accuracy: 0.9495 - discretized_accuracy: 0.9495\n",
            "Accuracy: 93.5%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utile esercizio: aggiungete rumore al generatore e verificate l'effetto sulla\n",
        "\"ground truth\"."
      ],
      "metadata": {
        "id": "NTY5fu8Hg7RE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cosa consegnare\n",
        "\n",
        "Ai fini del progetto dovete lavorare con la **griglia di default di dimensione 10x10, e con il rumore di default .002**\n",
        "\n",
        "il generatore deve essere trattato come una scatola nera: non modificatelo e non sfruttate la sua semantica, che si suppone ignota. Potete lavorare in modlaità \"flat\", se preferite.\n",
        "\n",
        "Dovete:\n",
        "\n",
        "1.   definire una funzione per il calcolo della accuratezza (potete prendere ispirazione dal cocice della cella precedente) \n",
        "2.   definire una rete neurale che prende in input theta e rho e restituisce out\n",
        "3.  misurare l'accuratezza della rete, che deve essere maggiore o uguale del 95%; l'accuratezza deve essere misurata su almeno 20000 dati\n",
        "4. perfezionare il modello cercando di diminuire il più possibile il numero dei parametri mantenendo una accuratezza superiore al 95%. Solo la vostra rete migliore deve essere consegnata.\n",
        "\n",
        "Dovete consegnare un UNICO notebook eseguibile su colab, che contenga il codice della rete, il suo sommario con il numero dei parametri, la storia di training, il codice per il calcolo della accuratezza e la sua valutazione sulla vostra rete.\n",
        "\n",
        "**N.B.** L'accuratezza deve essere superiore o uguale a 95%, ma non influisce in altro modo sulla valutazione. Il vostro punteggio dipenderà unicamente dal numero dei parametri: più è piccolo e più la vostra vaalutazione sarà elevata.  \n",
        "\n",
        "#Buon lavoro!\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jj4akvA24maJ"
      }
    }
  ]
}