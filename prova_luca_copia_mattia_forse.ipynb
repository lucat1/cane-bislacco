{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "L'obiettivo del progetto è apprendere mediante una rete neurale la trasformazione da punti del piano espressi in coordinate polari ad una rappresentazione basata su di una griglia discreta di dimensione 10x10, dove la cella della griglia ha valore 1 se contiene il punto, e 0 altrimenti.\n",
        "\n",
        "Il dataset supervisionato è fornito in questo notebook nella forma di una generatore. Il generatore deve essere considerato come una \"scatola nera\" il cui comportamento deve essere appreso. \n",
        "\n",
        "Dovete progettare una rete neurale in grado di raggiungere una accuratezza del 95%. Questa è una condizione necessaria per superare l'esame, ma l'accuratezza non influisce in altro modo sulla valutazione.  \n",
        "\n",
        "I modelli che raggiungono l'accuratezza attesa saranno invece valutati in modo inversamente proporzionale al numero dei loro parametri: **più il modello è piccolo, meglio è.**\n",
        "\n",
        "\n",
        "**Attenzione**: Qualunque soluzione che tragga vantaggio, diretto o indiretto, da meta-conoscenza relativa al generatore sarà automaticamente bocciato.\n"
      ],
      "metadata": {
        "id": "Zw_326KLT9dF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veniamo al generatore. Questo restituisce delle triple della forma\n",
        "((theta,rho),out) dove (theta,rho) sono le coordinate polari di un punto nel primo quadrante del piano, e out è una mappa 10x10 con \"1\" in correspondenza alla cella che contiene il punto, e \"0\" altrimenti.\n",
        "\n",
        "Settando  flat=True, la mappa 10x10 viene appiattita ad un vettore di dimensione 100. Potete utilizzare questa variante, se preferite. Nessuna altra modifica del generatore è ammessa. "
      ],
      "metadata": {
        "id": "iA01pkKbUt7Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creiamo una istanza del generatore con una griglia di dimensione 3x4"
      ],
      "metadata": {
        "id": "ZF-jlaqAWc2o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "... e osserviamo qualche esempio"
      ],
      "metadata": {
        "id": "b4hntQtSWjPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras import layers\n",
        "from keras import activations\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, Reshape, concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def polar_generator(batchsize,grid=(10,10),noise=.002,flat=False):\n",
        "  while True:\n",
        "    x = np.random.rand(batchsize)\n",
        "    y = np.random.rand(batchsize)\n",
        "    out = np.zeros((batchsize,grid[0],grid[1]))\n",
        "    xc = (x*grid[0]).astype(int)\n",
        "    yc = (y*grid[1]).astype(int)\n",
        "    for b in range(batchsize):\n",
        "      out[b,xc[b],yc[b]] = 1\n",
        "    #compute rho and theta and add some noise\n",
        "    rho = np.sqrt(x**2+y**2) + np.random.normal(scale=noise)\n",
        "    theta = np.arctan(y/np.maximum(x,.00001)) + np.random.normal(scale=noise)\n",
        "    if flat:\n",
        "      out = np.reshape(out,(batchsize,grid[0]*grid[1]))\n",
        "    yield ((theta,rho),out)\n",
        "\n",
        "n_train = 4000000\n",
        "n_test = 20000\n",
        "batch_size = 2048\n",
        "\n",
        "g1,g2 = 10,10\n",
        "gen = polar_generator(n_train+n_test,grid=(g1,g2),noise=0.002,flat=True)\n",
        "# (theta,rho),y = next(gen)\n",
        "(theta,rho),y = next(gen)\n",
        "\n",
        "x=np.array([i for i in zip(theta,rho)])\n",
        "\n",
        "# def xy(i):\n",
        "#   (theta,rho),y = i\n",
        "#   x=np.array([i for i in zip(theta,rho)])\n",
        "#   return (x,y)\n",
        "\n",
        "# gcd = np.gcd(n_train, n_test)\n",
        "# gen = pol.ipynbar_generator(gcd,grid=(size,size),noise=0.02)\n",
        "\n",
        "# x_train, y_train = xy(next(gen))\n",
        "# for i in range(int(n_train/gcd)-1):\n",
        "#   x,y = xy(next(gen))\n",
        "#   x_train = np.concatenate((x, x_train), axis=0)\n",
        "#   y_train = np.concatenate((y, y_train), axis=0)\n",
        "\n",
        "# x_test, y_test = xy(next(gen))\n",
        "# for i in range(int(n_train/gcd)-1):\n",
        "#   x,y = xy(next(gen))\n",
        "#   x_test = np.concatenate((x, x_test), axis=0)\n",
        "#   y_test = np.concatenate((y, y_test), axis=0)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=n_test/(n_train+n_test), shuffle=True, random_state=1)\n",
        "\n",
        "def discretized_accuracy(true_maps: tf.Tensor, my_maps: tf.Tensor) -> float:\n",
        "  equals = tf.equal(tf.argmax(true_maps, axis=1), tf.argmax(my_maps, axis=1))\n",
        "  return tf.cast(tf.math.count_nonzero(equals), tf.float64) / tf.cast(len(true_maps), tf.float64)"
      ],
      "metadata": {
        "id": "0Hh8TIUvKuXp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99f9dbbb-a757-433b-8825-931fcb87c1d8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-01-12 14:44:20.370834: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "network = keras.Sequential([\n",
        "layers.Flatten(),\n",
        "# layers.Dense(20, activation=keras.activations.relu),\n",
        "# layers.Dense(20, activation=keras.activations.tanh),\n",
        "# layers.Dropout(0.1), # Spegni il 10% dei neuroni a caso\n",
        "layers.Dense(4, activation=keras.activations.softsign),\n",
        "layers.Dense(8, activation=keras.activations.swish),\n",
        "# layers.BatchNormalization(),\n",
        "# layers.Dropout(0.5), # Spegni il 10% dei neuroni a caso\n",
        "layers.Dense(16, activation=keras.activations.relu),\n",
        "layers.Dense(4, activation=keras.activations.swish),\n",
        "# layers.Dropout(0.5), # Spegni il 10% dei neuroni a caso\n",
        "# layers.LayerNormalization(),\n",
        "# layers.BatchNormalization(),\n",
        "layers.Dense(100, activation=activations.softmax)\n",
        "])\n",
        "\n",
        "# Prima di poter usare il modello dobbiamo dire a Keras la dimensione dei nostri input\n",
        "# \"None\" vuol dire che il numero è ignoto/può cambiare (perché quante immagini alla volta g# può cambiare)\n",
        "network.build((None, 2))\n",
        "network.summary()\n",
        "\n",
        "network.compile(\n",
        "optimizer=keras.optimizers.Adam(learning_rate=1e-3), # Impostiamo SGD come ottimizzatore\n",
        "loss=keras.losses.CategoricalCrossentropy(),\n",
        "# loss=customLoss,\n",
        "metrics=['accuracy', discretized_accuracy]\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icsL8zRUZ1Y-",
        "outputId": "6c0cfb44-0ab8-4dfa-d764-c1acee39ddbe"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_2 (Flatten)         (None, 2)                 0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 4)                 12        \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 8)                 40        \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 16)                144       \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 4)                 68        \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 100)               500       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 764\n",
            "Trainable params: 764\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "network = keras.models.load_model(\"mymodel\")"
      ],
      "metadata": {
        "id": "lVV8wkELsrfz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "outputId": "fca02f98-a7c3-4c8c-9cb6-cf342cb97e49"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m network \u001b[38;5;241m=\u001b[39m \u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmymodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/usr/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[0;32m/usr/lib/python3.10/site-packages/keras/saving/legacy/saved_model/load.py:1138\u001b[0m, in \u001b[0;36mrevive_custom_object\u001b[0;34m(identifier, metadata)\u001b[0m\n\u001b[1;32m   1136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m revived_cls\u001b[38;5;241m.\u001b[39m_init_from_metadata(metadata)\n\u001b[1;32m   1137\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1138\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1139\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to restore custom object of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midentifier\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1140\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease make sure that any custom layers are included in the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1141\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`custom_objects` arg when calling `load_model()` and make sure \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1142\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthat all layers implement `get_config` and `from_config`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1143\u001b[0m     )\n",
            "\u001b[0;31mValueError\u001b[0m: Unable to restore custom object of type _tf_keras_metric. Please make sure that any custom layers are included in the `custom_objects` arg when calling `load_model()` and make sure that all layers implement `get_config` and `from_config`."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = network.fit(\n",
        "  x=x_train,\n",
        "  y=y_train,\n",
        "  epochs=5, # Addestriamo per 100 epoche\n",
        "  batch_size=batch_size, # Usiamo una batch size di 128\n",
        "  validation_data=(x_test, y_test),\n",
        "  callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0s1bjWjlxkEv",
        "outputId": "f5647715-11eb-43be-d6ed-530a58b4de15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1852/1954 [===========================>..] - ETA: 3s - loss: 0.0877 - accuracy: 0.9686 - discretized_accuracy: 0.9686"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score, _, acc  = network.evaluate(x_test, y_test,\n",
        "                            batch_size=batch_size)\n",
        "print('Test score:', score)\n",
        "print('Accuracy: {:.1f}%'.format(acc*100))"
      ],
      "metadata": {
        "id": "9EVrd8vdibxj",
        "outputId": "74421a38-c642-45d3-9e0e-f4ef0902a853",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0938 - accuracy: 0.9639 - discretized_accuracy: 0.9639\n",
            "Test score: 0.093800850212574\n",
            "Accuracy: 96.4%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "network.save(\"mymodel_2048\")\n",
        "network.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYGzYU7dnM11",
        "outputId": "7ac3cf65-3a8c-4e85-bb60-2a827a90f6a5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: mymodel_2048/assets\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_2 (Flatten)         (None, 2)                 0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 4)                 12        \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 8)                 40        \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 16)                144       \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 4)                 68        \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 100)               500       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 764\n",
            "Trainable params: 764\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gen = polar_generator(20000,grid=(g1,g2),noise=0.002,flat=True)\n",
        "\n",
        "accs = 0.0\n",
        "iters = 100\n",
        "for x in range(iters):\n",
        "  (theta,rho),y = next(gen)\n",
        "  x=np.array([i for i in zip(theta,rho)])\n",
        "\n",
        "  score, _, acc = network.evaluate(x, y, batch_size=batch_size)\n",
        "  accs += acc\n",
        "\n",
        "print('Accuracy: {:.1f}%'.format(accs/iters*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSuIej-WhztW",
        "outputId": "8c9a922d-2110-4b3c-9b19-cb406e71b4dc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0989 - accuracy: 0.9601 - discretized_accuracy: 0.9602\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0995 - accuracy: 0.9589 - discretized_accuracy: 0.9589\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0920 - accuracy: 0.9639 - discretized_accuracy: 0.9638\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1442 - accuracy: 0.9348 - discretized_accuracy: 0.9347\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0967 - accuracy: 0.9605 - discretized_accuracy: 0.9605\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1405 - accuracy: 0.9387 - discretized_accuracy: 0.9385\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1191 - accuracy: 0.9492 - discretized_accuracy: 0.9493\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0993 - accuracy: 0.9616 - discretized_accuracy: 0.9617\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0969 - accuracy: 0.9608 - discretized_accuracy: 0.9607\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0995 - accuracy: 0.9607 - discretized_accuracy: 0.9607\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.1198 - accuracy: 0.9481 - discretized_accuracy: 0.9481\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0932 - accuracy: 0.9636 - discretized_accuracy: 0.9638\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0999 - accuracy: 0.9596 - discretized_accuracy: 0.9599\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1105 - accuracy: 0.9539 - discretized_accuracy: 0.9541\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1105 - accuracy: 0.9542 - discretized_accuracy: 0.9543\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1015 - accuracy: 0.9577 - discretized_accuracy: 0.9576\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1289 - accuracy: 0.9420 - discretized_accuracy: 0.9422\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1024 - accuracy: 0.9580 - discretized_accuracy: 0.9578\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.1255 - accuracy: 0.9451 - discretized_accuracy: 0.9452\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0992 - accuracy: 0.9582 - discretized_accuracy: 0.9583\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0981 - accuracy: 0.9607 - discretized_accuracy: 0.9607\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0983 - accuracy: 0.9604 - discretized_accuracy: 0.9604\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0976 - accuracy: 0.9595 - discretized_accuracy: 0.9596\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1060 - accuracy: 0.9567 - discretized_accuracy: 0.9567\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0953 - accuracy: 0.9639 - discretized_accuracy: 0.9639\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0944 - accuracy: 0.9619 - discretized_accuracy: 0.9621\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1207 - accuracy: 0.9476 - discretized_accuracy: 0.9475\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1219 - accuracy: 0.9460 - discretized_accuracy: 0.9461\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0972 - accuracy: 0.9610 - discretized_accuracy: 0.9610\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0915 - accuracy: 0.9657 - discretized_accuracy: 0.9655\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0973 - accuracy: 0.9619 - discretized_accuracy: 0.9619\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1095 - accuracy: 0.9522 - discretized_accuracy: 0.9521\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0936 - accuracy: 0.9624 - discretized_accuracy: 0.9623\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.1024 - accuracy: 0.9580 - discretized_accuracy: 0.9580\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1104 - accuracy: 0.9527 - discretized_accuracy: 0.9526\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.1147 - accuracy: 0.9507 - discretized_accuracy: 0.9506\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1045 - accuracy: 0.9571 - discretized_accuracy: 0.9573\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.1064 - accuracy: 0.9553 - discretized_accuracy: 0.9552\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.1003 - accuracy: 0.9579 - discretized_accuracy: 0.9580\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1201 - accuracy: 0.9471 - discretized_accuracy: 0.9469\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1152 - accuracy: 0.9496 - discretized_accuracy: 0.9497\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0908 - accuracy: 0.9651 - discretized_accuracy: 0.9653\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1156 - accuracy: 0.9499 - discretized_accuracy: 0.9498\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1151 - accuracy: 0.9487 - discretized_accuracy: 0.9487\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1017 - accuracy: 0.9573 - discretized_accuracy: 0.9573\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.1131 - accuracy: 0.9510 - discretized_accuracy: 0.9508\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1016 - accuracy: 0.9571 - discretized_accuracy: 0.9571\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0934 - accuracy: 0.9639 - discretized_accuracy: 0.9640\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0970 - accuracy: 0.9611 - discretized_accuracy: 0.9609\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1020 - accuracy: 0.9580 - discretized_accuracy: 0.9580\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1568 - accuracy: 0.9306 - discretized_accuracy: 0.9306\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1061 - accuracy: 0.9543 - discretized_accuracy: 0.9540\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0961 - accuracy: 0.9614 - discretized_accuracy: 0.9612\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.1274 - accuracy: 0.9443 - discretized_accuracy: 0.9445\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0929 - accuracy: 0.9629 - discretized_accuracy: 0.9628\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0986 - accuracy: 0.9592 - discretized_accuracy: 0.9592\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1125 - accuracy: 0.9504 - discretized_accuracy: 0.9502\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0973 - accuracy: 0.9603 - discretized_accuracy: 0.9604\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1017 - accuracy: 0.9586 - discretized_accuracy: 0.9588\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1024 - accuracy: 0.9571 - discretized_accuracy: 0.9571\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.1291 - accuracy: 0.9441 - discretized_accuracy: 0.9440\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0999 - accuracy: 0.9594 - discretized_accuracy: 0.9594\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0980 - accuracy: 0.9603 - discretized_accuracy: 0.9603\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0961 - accuracy: 0.9615 - discretized_accuracy: 0.9617\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1035 - accuracy: 0.9565 - discretized_accuracy: 0.9566\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0978 - accuracy: 0.9609 - discretized_accuracy: 0.9608\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1044 - accuracy: 0.9564 - discretized_accuracy: 0.9564\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1492 - accuracy: 0.9309 - discretized_accuracy: 0.9308\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0956 - accuracy: 0.9615 - discretized_accuracy: 0.9615\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1006 - accuracy: 0.9593 - discretized_accuracy: 0.9595\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1293 - accuracy: 0.9426 - discretized_accuracy: 0.9424\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1006 - accuracy: 0.9590 - discretized_accuracy: 0.9589\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1110 - accuracy: 0.9527 - discretized_accuracy: 0.9526\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.1194 - accuracy: 0.9474 - discretized_accuracy: 0.9476\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.1063 - accuracy: 0.9563 - discretized_accuracy: 0.9563\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0952 - accuracy: 0.9627 - discretized_accuracy: 0.9629\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1125 - accuracy: 0.9505 - discretized_accuracy: 0.9505\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1369 - accuracy: 0.9370 - discretized_accuracy: 0.9370\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0962 - accuracy: 0.9616 - discretized_accuracy: 0.9616\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1039 - accuracy: 0.9564 - discretized_accuracy: 0.9565\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.1455 - accuracy: 0.9341 - discretized_accuracy: 0.9339\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1008 - accuracy: 0.9579 - discretized_accuracy: 0.9579\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.1029 - accuracy: 0.9564 - discretized_accuracy: 0.9565\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1026 - accuracy: 0.9575 - discretized_accuracy: 0.9574\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0980 - accuracy: 0.9613 - discretized_accuracy: 0.9612\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1000 - accuracy: 0.9592 - discretized_accuracy: 0.9591\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1075 - accuracy: 0.9546 - discretized_accuracy: 0.9545\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1200 - accuracy: 0.9479 - discretized_accuracy: 0.9482\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1361 - accuracy: 0.9382 - discretized_accuracy: 0.9382\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0938 - accuracy: 0.9623 - discretized_accuracy: 0.9622\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.1003 - accuracy: 0.9590 - discretized_accuracy: 0.9591\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1662 - accuracy: 0.9276 - discretized_accuracy: 0.9276\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1372 - accuracy: 0.9392 - discretized_accuracy: 0.9394\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1096 - accuracy: 0.9518 - discretized_accuracy: 0.9520\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1152 - accuracy: 0.9502 - discretized_accuracy: 0.9501\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.1367 - accuracy: 0.9406 - discretized_accuracy: 0.9407\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1023 - accuracy: 0.9577 - discretized_accuracy: 0.9578\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.1214 - accuracy: 0.9466 - discretized_accuracy: 0.9464\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1354 - accuracy: 0.9378 - discretized_accuracy: 0.9376\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1114 - accuracy: 0.9523 - discretized_accuracy: 0.9524\n",
            "Accuracy: 95.4%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utile esercizio: aggiungete rumore al generatore e verificate l'effetto sulla\n",
        "\"ground truth\"."
      ],
      "metadata": {
        "id": "NTY5fu8Hg7RE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cosa consegnare\n",
        "\n",
        "Ai fini del progetto dovete lavorare con la **griglia di default di dimensione 10x10, e con il rumore di default .002**\n",
        "\n",
        "il generatore deve essere trattato come una scatola nera: non modificatelo e non sfruttate la sua semantica, che si suppone ignota. Potete lavorare in modlaità \"flat\", se preferite.\n",
        "\n",
        "Dovete:\n",
        "\n",
        "1.   definire una funzione per il calcolo della accuratezza (potete prendere ispirazione dal cocice della cella precedente) \n",
        "2.   definire una rete neurale che prende in input theta e rho e restituisce out\n",
        "3.  misurare l'accuratezza della rete, che deve essere maggiore o uguale del 95%; l'accuratezza deve essere misurata su almeno 20000 dati\n",
        "4. perfezionare il modello cercando di diminuire il più possibile il numero dei parametri mantenendo una accuratezza superiore al 95%. Solo la vostra rete migliore deve essere consegnata.\n",
        "\n",
        "Dovete consegnare un UNICO notebook eseguibile su colab, che contenga il codice della rete, il suo sommario con il numero dei parametri, la storia di training, il codice per il calcolo della accuratezza e la sua valutazione sulla vostra rete.\n",
        "\n",
        "**N.B.** L'accuratezza deve essere superiore o uguale a 95%, ma non influisce in altro modo sulla valutazione. Il vostro punteggio dipenderà unicamente dal numero dei parametri: più è piccolo e più la vostra vaalutazione sarà elevata.  \n",
        "\n",
        "#Buon lavoro!\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jj4akvA24maJ"
      }
    }
  ]
}