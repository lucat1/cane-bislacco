{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "L'obiettivo del progetto è apprendere mediante una rete neurale la trasformazione da punti del piano espressi in coordinate polari ad una rappresentazione basata su di una griglia discreta di dimensione 10x10, dove la cella della griglia ha valore 1 se contiene il punto, e 0 altrimenti.\n",
        "\n",
        "Il dataset supervisionato è fornito in questo notebook nella forma di una generatore. Il generatore deve essere considerato come una \"scatola nera\" il cui comportamento deve essere appreso. \n",
        "\n",
        "Dovete progettare una rete neurale in grado di raggiungere una accuratezza del 95%. Questa è una condizione necessaria per superare l'esame, ma l'accuratezza non influisce in altro modo sulla valutazione.  \n",
        "\n",
        "I modelli che raggiungono l'accuratezza attesa saranno invece valutati in modo inversamente proporzionale al numero dei loro parametri: **più il modello è piccolo, meglio è.**\n",
        "\n",
        "\n",
        "**Attenzione**: Qualunque soluzione che tragga vantaggio, diretto o indiretto, da meta-conoscenza relativa al generatore sarà automaticamente bocciato.\n"
      ],
      "metadata": {
        "id": "Zw_326KLT9dF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veniamo al generatore. Questo restituisce delle triple della forma\n",
        "((theta,rho),out) dove (theta,rho) sono le coordinate polari di un punto nel primo quadrante del piano, e out è una mappa 10x10 con \"1\" in correspondenza alla cella che contiene il punto, e \"0\" altrimenti.\n",
        "\n",
        "Settando  flat=True, la mappa 10x10 viene appiattita ad un vettore di dimensione 100. Potete utilizzare questa variante, se preferite. Nessuna altra modifica del generatore è ammessa. "
      ],
      "metadata": {
        "id": "iA01pkKbUt7Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creiamo una istanza del generatore con una griglia di dimensione 3x4"
      ],
      "metadata": {
        "id": "ZF-jlaqAWc2o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "... e osserviamo qualche esempio"
      ],
      "metadata": {
        "id": "b4hntQtSWjPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras import layers\n",
        "from keras import activations\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, Reshape, concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def polar_generator(batchsize,grid=(10,10),noise=.002,flat=False):\n",
        "  while True:\n",
        "    x = np.random.rand(batchsize)\n",
        "    y = np.random.rand(batchsize)\n",
        "    out = np.zeros((batchsize,grid[0],grid[1]))\n",
        "    xc = (x*grid[0]).astype(int)\n",
        "    yc = (y*grid[1]).astype(int)\n",
        "    for b in range(batchsize):\n",
        "      out[b,xc[b],yc[b]] = 1\n",
        "    #compute rho and theta and add some noise\n",
        "    rho = np.sqrt(x**2+y**2) + np.random.normal(scale=noise)\n",
        "    theta = np.arctan(y/np.maximum(x,.00001)) + np.random.normal(scale=noise)\n",
        "    if flat:\n",
        "      out = np.reshape(out,(batchsize,grid[0]*grid[1]))\n",
        "    yield ((theta,rho),out)\n",
        "\n",
        "n_train = 4000000\n",
        "n_test = 20000\n",
        "batch_size = 2048\n",
        "\n",
        "g1,g2 = 10,10\n",
        "gen = polar_generator(n_train+n_test,grid=(g1,g2),noise=0.002,flat=True)\n",
        "# (theta,rho),y = next(gen)\n",
        "(theta,rho),y = next(gen)\n",
        "\n",
        "x=np.array([i for i in zip(theta,rho)])\n",
        "\n",
        "# def xy(i):\n",
        "#   (theta,rho),y = i\n",
        "#   x=np.array([i for i in zip(theta,rho)])\n",
        "#   return (x,y)\n",
        "\n",
        "# gcd = np.gcd(n_train, n_test)\n",
        "# gen = pol.ipynbar_generator(gcd,grid=(size,size),noise=0.02)\n",
        "\n",
        "# x_train, y_train = xy(next(gen))\n",
        "# for i in range(int(n_train/gcd)-1):\n",
        "#   x,y = xy(next(gen))\n",
        "#   x_train = np.concatenate((x, x_train), axis=0)\n",
        "#   y_train = np.concatenate((y, y_train), axis=0)\n",
        "\n",
        "# x_test, y_test = xy(next(gen))\n",
        "# for i in range(int(n_train/gcd)-1):\n",
        "#   x,y = xy(next(gen))\n",
        "#   x_test = np.concatenate((x, x_test), axis=0)\n",
        "#   y_test = np.concatenate((y, y_test), axis=0)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=n_test/(n_train+n_test), shuffle=True, random_state=1)\n",
        "\n",
        "\n",
        "def discretized_accuracy(true_maps: tf.Tensor, my_maps: tf.Tensor) -> float:\n",
        "  equals = tf.equal(tf.argmax(true_maps, axis=1), tf.argmax(my_maps, axis=1))\n",
        "  return tf.cast(tf.math.count_nonzero(equals), tf.float64) / tf.cast(len(true_maps), tf.float64)"
      ],
      "metadata": {
        "id": "0Hh8TIUvKuXp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "network = keras.Sequential([\n",
        "layers.Flatten(),\n",
        "# layers.Dense(20, activation=keras.activations.relu),\n",
        "# layers.Dense(20, activation=keras.activations.tanh),\n",
        "# layers.Dropout(0.1), # Spegni il 10% dei neuroni a caso\n",
        "layers.Dense(4, activation=keras.activations.softsign),\n",
        "layers.Dense(6, activation=keras.activations.swish),\n",
        "layers.Dense(6, activation=keras.activations.tanh),\n",
        "# layers.BatchNormalization(),\n",
        "# layers.Dropout(0.5), # Spegni il 10% dei neuroni a caso\n",
        "layers.Dense(6, activation=keras.activations.selu,kernel_initializer='lecun_normal'),\n",
        "layers.Dense(6, activation=keras.activations.swish),\n",
        "# layers.Dropout(0.5), # Spegni il 10% dei neuroni a caso \n",
        "# layers.LayerNormalization(),\n",
        "# layers.BatchNormalization(),\n",
        "layers.Dense(100, activation=activations.softmax)\n",
        "])\n",
        "\n",
        "# Prima di poter usare il modello dobbiamo dire a Keras la dimensione dei nostri input\n",
        "# \"None\" vuol dire che il numero è ignoto/può cambiare (perché quante immagini alla volta g# può cambiare)\n",
        "network.build((None, 2))\n",
        "network.summary()\n",
        "\n",
        "network.compile(\n",
        "optimizer=keras.optimizers.Adam(learning_rate=1e-3), # Impostiamo SGD come ottimizzatore\n",
        "loss=keras.losses.CategoricalCrossentropy(),\n",
        "# loss=customLoss,\n",
        "metrics=['accuracy', discretized_accuracy]\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icsL8zRUZ1Y-",
        "outputId": "827cdb5f-0c77-41d7-9510-263cb4d4c7e8"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_11 (Flatten)        (None, 2)                 0         \n",
            "                                                                 \n",
            " dense_82 (Dense)            (None, 4)                 12        \n",
            "                                                                 \n",
            " dense_83 (Dense)            (None, 6)                 30        \n",
            "                                                                 \n",
            " dense_84 (Dense)            (None, 6)                 42        \n",
            "                                                                 \n",
            " dense_85 (Dense)            (None, 6)                 42        \n",
            "                                                                 \n",
            " dense_86 (Dense)            (None, 6)                 42        \n",
            "                                                                 \n",
            " dense_87 (Dense)            (None, 100)               700       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 868\n",
            "Trainable params: 868\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "network = keras.models.load_model(\"mymodel\")"
      ],
      "metadata": {
        "id": "lVV8wkELsrfz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "outputId": "fc060299-b885-402f-cd36-5d6899aa0d32"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-b8cf9f13c92e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnetwork\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mymodel\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'No file or directory found at {filepath_str}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: No file or directory found at mymodel"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = network.fit(\n",
        "x=x_train,\n",
        "y=y_train,\n",
        "epochs=15, # Addestriamo per 100 epoche\n",
        "batch_size=batch_size, # Usiamo una batch size di 128\n",
        "validation_data=(x_test, y_test),\n",
        "callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0s1bjWjlxkEv",
        "outputId": "f7dbba89-bf20-4f61-8425-1564cc849cd0"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "1954/1954 [==============================] - 10s 5ms/step - loss: 1.7351 - accuracy: 0.6035 - discretized_accuracy: 0.6036 - val_loss: 0.6182 - val_accuracy: 0.8576 - val_discretized_accuracy: 0.8577\n",
            "Epoch 2/15\n",
            "1954/1954 [==============================] - 9s 5ms/step - loss: 0.4318 - accuracy: 0.8961 - discretized_accuracy: 0.8961 - val_loss: 0.3199 - val_accuracy: 0.9176 - val_discretized_accuracy: 0.9178\n",
            "Epoch 3/15\n",
            "1954/1954 [==============================] - 9s 5ms/step - loss: 0.2668 - accuracy: 0.9339 - discretized_accuracy: 0.9339 - val_loss: 0.2269 - val_accuracy: 0.9448 - val_discretized_accuracy: 0.9450\n",
            "Epoch 4/15\n",
            "1954/1954 [==============================] - 9s 5ms/step - loss: 0.2035 - accuracy: 0.9507 - discretized_accuracy: 0.9507 - val_loss: 0.1843 - val_accuracy: 0.9546 - val_discretized_accuracy: 0.9546\n",
            "Epoch 5/15\n",
            "1954/1954 [==============================] - 9s 5ms/step - loss: 0.1696 - accuracy: 0.9595 - discretized_accuracy: 0.9595 - val_loss: 0.1581 - val_accuracy: 0.9625 - val_discretized_accuracy: 0.9625\n",
            "Epoch 6/15\n",
            "1954/1954 [==============================] - 9s 5ms/step - loss: 0.1482 - accuracy: 0.9648 - discretized_accuracy: 0.9648 - val_loss: 0.1416 - val_accuracy: 0.9633 - val_discretized_accuracy: 0.9634\n",
            "Epoch 7/15\n",
            "1954/1954 [==============================] - 9s 5ms/step - loss: 0.1333 - accuracy: 0.9680 - discretized_accuracy: 0.9680 - val_loss: 0.1275 - val_accuracy: 0.9683 - val_discretized_accuracy: 0.9684\n",
            "Epoch 8/15\n",
            "1954/1954 [==============================] - 9s 5ms/step - loss: 0.1223 - accuracy: 0.9703 - discretized_accuracy: 0.9703 - val_loss: 0.1187 - val_accuracy: 0.9689 - val_discretized_accuracy: 0.9690\n",
            "Epoch 9/15\n",
            "1954/1954 [==============================] - 9s 5ms/step - loss: 0.1138 - accuracy: 0.9720 - discretized_accuracy: 0.9720 - val_loss: 0.1094 - val_accuracy: 0.9733 - val_discretized_accuracy: 0.9733\n",
            "Epoch 10/15\n",
            "1954/1954 [==============================] - 9s 5ms/step - loss: 0.1069 - accuracy: 0.9733 - discretized_accuracy: 0.9733 - val_loss: 0.1034 - val_accuracy: 0.9739 - val_discretized_accuracy: 0.9739\n",
            "Epoch 11/15\n",
            "1954/1954 [==============================] - 9s 5ms/step - loss: 0.1013 - accuracy: 0.9741 - discretized_accuracy: 0.9742 - val_loss: 0.0981 - val_accuracy: 0.9746 - val_discretized_accuracy: 0.9747\n",
            "Epoch 12/15\n",
            "1954/1954 [==============================] - 9s 5ms/step - loss: 0.0963 - accuracy: 0.9753 - discretized_accuracy: 0.9753 - val_loss: 0.0977 - val_accuracy: 0.9712 - val_discretized_accuracy: 0.9711\n",
            "Epoch 13/15\n",
            "1954/1954 [==============================] - 9s 4ms/step - loss: 0.0924 - accuracy: 0.9757 - discretized_accuracy: 0.9757 - val_loss: 0.0897 - val_accuracy: 0.9768 - val_discretized_accuracy: 0.9769\n",
            "Epoch 14/15\n",
            "1954/1954 [==============================] - 9s 5ms/step - loss: 0.0891 - accuracy: 0.9760 - discretized_accuracy: 0.9760 - val_loss: 0.0854 - val_accuracy: 0.9789 - val_discretized_accuracy: 0.9788\n",
            "Epoch 15/15\n",
            "1954/1954 [==============================] - 9s 4ms/step - loss: 0.0858 - accuracy: 0.9768 - discretized_accuracy: 0.9768 - val_loss: 0.0865 - val_accuracy: 0.9742 - val_discretized_accuracy: 0.9741\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score, _, acc  = network.evaluate(x_test, y_test,\n",
        "                            batch_size=batch_size)\n",
        "print('Test score:', score)\n",
        "print('Accuracy: {:.1f}%'.format(acc*100))"
      ],
      "metadata": {
        "id": "9EVrd8vdibxj",
        "outputId": "ff95cb6f-40a7-478d-835a-4160e3bc5a96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0865 - accuracy: 0.9742 - discretized_accuracy: 0.9741\n",
            "Test score: 0.08646036684513092\n",
            "Accuracy: 97.4%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "network.save(\"mymodel_2048\")\n",
        "network.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYGzYU7dnM11",
        "outputId": "69efe3f9-e279-4903-c49a-ab4d3ea5a674"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_10 (Flatten)        (None, 2)                 0         \n",
            "                                                                 \n",
            " dense_75 (Dense)            (None, 4)                 12        \n",
            "                                                                 \n",
            " dense_76 (Dense)            (None, 6)                 30        \n",
            "                                                                 \n",
            " dense_77 (Dense)            (None, 6)                 42        \n",
            "                                                                 \n",
            " dense_78 (Dense)            (None, 6)                 42        \n",
            "                                                                 \n",
            " dense_79 (Dense)            (None, 6)                 42        \n",
            "                                                                 \n",
            " dense_80 (Dense)            (None, 6)                 42        \n",
            "                                                                 \n",
            " dense_81 (Dense)            (None, 100)               700       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 910\n",
            "Trainable params: 910\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gen = polar_generator(20000,grid=(g1,g2),noise=0.002,flat=True)\n",
        "accs = 0.0\n",
        "lower = 0\n",
        "iters = 100\n",
        "for x in range(iters):\n",
        "  (theta,rho),y = next(gen)\n",
        "  x=np.array([i for i in zip(theta,rho)])\n",
        "\n",
        "  score, _, acc = network.evaluate(x, y, batch_size=batch_size)\n",
        "  accs += acc\n",
        "  if acc < 0.95:\n",
        "    lower += 1\n",
        "\n",
        "print('------------------------')\n",
        "print('Accuracy: {:.1f}%'.format(accs/iters*100))\n",
        "print('Lower than 95%: {}/{}'.format(lower, iters))\n",
        "print('------------------------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSuIej-WhztW",
        "outputId": "43794e79-32d6-4544-bd77-4c9ac30b3630"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0952 - accuracy: 0.9662 - discretized_accuracy: 0.9661\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.1120 - accuracy: 0.9538 - discretized_accuracy: 0.9539\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0889 - accuracy: 0.9722 - discretized_accuracy: 0.9723\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0911 - accuracy: 0.9711 - discretized_accuracy: 0.9711\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0953 - accuracy: 0.9654 - discretized_accuracy: 0.9653\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0948 - accuracy: 0.9664 - discretized_accuracy: 0.9664\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0995 - accuracy: 0.9618 - discretized_accuracy: 0.9616\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0950 - accuracy: 0.9640 - discretized_accuracy: 0.9639\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0893 - accuracy: 0.9722 - discretized_accuracy: 0.9722\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0871 - accuracy: 0.9744 - discretized_accuracy: 0.9745\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0865 - accuracy: 0.9728 - discretized_accuracy: 0.9727\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0864 - accuracy: 0.9735 - discretized_accuracy: 0.9734\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.1045 - accuracy: 0.9564 - discretized_accuracy: 0.9565\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0996 - accuracy: 0.9603 - discretized_accuracy: 0.9603\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0997 - accuracy: 0.9622 - discretized_accuracy: 0.9622\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0856 - accuracy: 0.9746 - discretized_accuracy: 0.9746\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0972 - accuracy: 0.9637 - discretized_accuracy: 0.9634\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.1012 - accuracy: 0.9608 - discretized_accuracy: 0.9608\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1220 - accuracy: 0.9428 - discretized_accuracy: 0.9427\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0956 - accuracy: 0.9658 - discretized_accuracy: 0.9657\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0874 - accuracy: 0.9725 - discretized_accuracy: 0.9724\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0976 - accuracy: 0.9632 - discretized_accuracy: 0.9633\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.1092 - accuracy: 0.9561 - discretized_accuracy: 0.9562\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0909 - accuracy: 0.9696 - discretized_accuracy: 0.9697\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1085 - accuracy: 0.9554 - discretized_accuracy: 0.9555\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.1100 - accuracy: 0.9560 - discretized_accuracy: 0.9560\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0830 - accuracy: 0.9752 - discretized_accuracy: 0.9752\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1178 - accuracy: 0.9475 - discretized_accuracy: 0.9476\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0893 - accuracy: 0.9716 - discretized_accuracy: 0.9717\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.1016 - accuracy: 0.9610 - discretized_accuracy: 0.9608\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0857 - accuracy: 0.9757 - discretized_accuracy: 0.9756\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0885 - accuracy: 0.9708 - discretized_accuracy: 0.9709\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0886 - accuracy: 0.9722 - discretized_accuracy: 0.9723\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0914 - accuracy: 0.9685 - discretized_accuracy: 0.9685\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0964 - accuracy: 0.9634 - discretized_accuracy: 0.9633\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0902 - accuracy: 0.9709 - discretized_accuracy: 0.9709\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0939 - accuracy: 0.9676 - discretized_accuracy: 0.9676\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0979 - accuracy: 0.9615 - discretized_accuracy: 0.9617\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.1006 - accuracy: 0.9615 - discretized_accuracy: 0.9615\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.1035 - accuracy: 0.9566 - discretized_accuracy: 0.9566\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.1221 - accuracy: 0.9448 - discretized_accuracy: 0.9445\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0911 - accuracy: 0.9689 - discretized_accuracy: 0.9690\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0877 - accuracy: 0.9713 - discretized_accuracy: 0.9715\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0828 - accuracy: 0.9783 - discretized_accuracy: 0.9784\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0841 - accuracy: 0.9785 - discretized_accuracy: 0.9785\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.1122 - accuracy: 0.9517 - discretized_accuracy: 0.9518\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0893 - accuracy: 0.9716 - discretized_accuracy: 0.9716\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0845 - accuracy: 0.9761 - discretized_accuracy: 0.9762\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0974 - accuracy: 0.9628 - discretized_accuracy: 0.9629\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0954 - accuracy: 0.9647 - discretized_accuracy: 0.9646\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.1083 - accuracy: 0.9535 - discretized_accuracy: 0.9535\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.1053 - accuracy: 0.9566 - discretized_accuracy: 0.9566\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0859 - accuracy: 0.9737 - discretized_accuracy: 0.9738\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0871 - accuracy: 0.9754 - discretized_accuracy: 0.9754\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0848 - accuracy: 0.9743 - discretized_accuracy: 0.9743\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0842 - accuracy: 0.9752 - discretized_accuracy: 0.9752\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.1140 - accuracy: 0.9510 - discretized_accuracy: 0.9510\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0912 - accuracy: 0.9679 - discretized_accuracy: 0.9681\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0947 - accuracy: 0.9675 - discretized_accuracy: 0.9673\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0996 - accuracy: 0.9613 - discretized_accuracy: 0.9612\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.1122 - accuracy: 0.9505 - discretized_accuracy: 0.9504\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0858 - accuracy: 0.9751 - discretized_accuracy: 0.9751\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0864 - accuracy: 0.9742 - discretized_accuracy: 0.9743\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0982 - accuracy: 0.9647 - discretized_accuracy: 0.9648\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0994 - accuracy: 0.9632 - discretized_accuracy: 0.9632\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0995 - accuracy: 0.9631 - discretized_accuracy: 0.9629\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.1775 - accuracy: 0.9222 - discretized_accuracy: 0.9222\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0850 - accuracy: 0.9764 - discretized_accuracy: 0.9763\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0862 - accuracy: 0.9755 - discretized_accuracy: 0.9756\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0860 - accuracy: 0.9759 - discretized_accuracy: 0.9760\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0916 - accuracy: 0.9697 - discretized_accuracy: 0.9697\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.1627 - accuracy: 0.9254 - discretized_accuracy: 0.9257\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0937 - accuracy: 0.9679 - discretized_accuracy: 0.9680\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0887 - accuracy: 0.9744 - discretized_accuracy: 0.9745\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.1217 - accuracy: 0.9458 - discretized_accuracy: 0.9460\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1051 - accuracy: 0.9575 - discretized_accuracy: 0.9577\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.1096 - accuracy: 0.9537 - discretized_accuracy: 0.9538\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0873 - accuracy: 0.9750 - discretized_accuracy: 0.9751\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.1008 - accuracy: 0.9611 - discretized_accuracy: 0.9608\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0987 - accuracy: 0.9607 - discretized_accuracy: 0.9609\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0976 - accuracy: 0.9620 - discretized_accuracy: 0.9618\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0850 - accuracy: 0.9757 - discretized_accuracy: 0.9757\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0864 - accuracy: 0.9728 - discretized_accuracy: 0.9728\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0825 - accuracy: 0.9784 - discretized_accuracy: 0.9784\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0927 - accuracy: 0.9692 - discretized_accuracy: 0.9692\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.1272 - accuracy: 0.9428 - discretized_accuracy: 0.9427\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0844 - accuracy: 0.9772 - discretized_accuracy: 0.9772\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.1140 - accuracy: 0.9517 - discretized_accuracy: 0.9518\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0882 - accuracy: 0.9729 - discretized_accuracy: 0.9728\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0950 - accuracy: 0.9650 - discretized_accuracy: 0.9649\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0995 - accuracy: 0.9624 - discretized_accuracy: 0.9624\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0899 - accuracy: 0.9719 - discretized_accuracy: 0.9719\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0951 - accuracy: 0.9676 - discretized_accuracy: 0.9675\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1220 - accuracy: 0.9466 - discretized_accuracy: 0.9466\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0858 - accuracy: 0.9743 - discretized_accuracy: 0.9743\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.1206 - accuracy: 0.9488 - discretized_accuracy: 0.9490\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.1416 - accuracy: 0.9369 - discretized_accuracy: 0.9370\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.1045 - accuracy: 0.9557 - discretized_accuracy: 0.9555\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0880 - accuracy: 0.9711 - discretized_accuracy: 0.9711\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.1054 - accuracy: 0.9550 - discretized_accuracy: 0.9551\n",
            "------------------------\n",
            "Accuracy: 96.4%\n",
            "Lower than 95%: 10/100\n",
            "------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utile esercizio: aggiungete rumore al generatore e verificate l'effetto sulla\n",
        "\"ground truth\"."
      ],
      "metadata": {
        "id": "NTY5fu8Hg7RE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cosa consegnare\n",
        "\n",
        "Ai fini del progetto dovete lavorare con la **griglia di default di dimensione 10x10, e con il rumore di default .002**\n",
        "\n",
        "il generatore deve essere trattato come una scatola nera: non modificatelo e non sfruttate la sua semantica, che si suppone ignota. Potete lavorare in modlaità \"flat\", se preferite.\n",
        "\n",
        "Dovete:\n",
        "\n",
        "1.   definire una funzione per il calcolo della accuratezza (potete prendere ispirazione dal cocice della cella precedente) \n",
        "2.   definire una rete neurale che prende in input theta e rho e restituisce out\n",
        "3.  misurare l'accuratezza della rete, che deve essere maggiore o uguale del 95%; l'accuratezza deve essere misurata su almeno 20000 dati\n",
        "4. perfezionare il modello cercando di diminuire il più possibile il numero dei parametri mantenendo una accuratezza superiore al 95%. Solo la vostra rete migliore deve essere consegnata.\n",
        "\n",
        "Dovete consegnare un UNICO notebook eseguibile su colab, che contenga il codice della rete, il suo sommario con il numero dei parametri, la storia di training, il codice per il calcolo della accuratezza e la sua valutazione sulla vostra rete.\n",
        "\n",
        "**N.B.** L'accuratezza deve essere superiore o uguale a 95%, ma non influisce in altro modo sulla valutazione. Il vostro punteggio dipenderà unicamente dal numero dei parametri: più è piccolo e più la vostra vaalutazione sarà elevata.  \n",
        "\n",
        "#Buon lavoro!\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jj4akvA24maJ"
      }
    }
  ]
}